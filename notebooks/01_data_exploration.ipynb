{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dade758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying data for patient: p000001.psv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR</th>\n",
       "      <th>O2Sat</th>\n",
       "      <th>Temp</th>\n",
       "      <th>SBP</th>\n",
       "      <th>MAP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>Resp</th>\n",
       "      <th>EtCO2</th>\n",
       "      <th>BaseExcess</th>\n",
       "      <th>HCO3</th>\n",
       "      <th>...</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Fibrinogen</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Unit1</th>\n",
       "      <th>Unit2</th>\n",
       "      <th>HospAdmTime</th>\n",
       "      <th>ICULOS</th>\n",
       "      <th>SepsisLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>75.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.0</td>\n",
       "      <td>86.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103.0</td>\n",
       "      <td>88.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.0</td>\n",
       "      <td>91.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HR  O2Sat  Temp    SBP    MAP  DBP  Resp  EtCO2  BaseExcess  HCO3  ...  \\\n",
       "0    NaN    NaN   NaN    NaN    NaN  NaN   NaN    NaN         NaN   NaN  ...   \n",
       "1   97.0   95.0   NaN   98.0  75.33  NaN  19.0    NaN         NaN   NaN  ...   \n",
       "2   89.0   99.0   NaN  122.0  86.00  NaN  22.0    NaN         NaN   NaN  ...   \n",
       "3   90.0   95.0   NaN    NaN    NaN  NaN  30.0    NaN        24.0   NaN  ...   \n",
       "4  103.0   88.5   NaN  122.0  91.33  NaN  24.5    NaN         NaN   NaN  ...   \n",
       "\n",
       "   WBC  Fibrinogen  Platelets    Age  Gender  Unit1  Unit2  HospAdmTime  \\\n",
       "0  NaN         NaN        NaN  83.14       0    NaN    NaN        -0.03   \n",
       "1  NaN         NaN        NaN  83.14       0    NaN    NaN        -0.03   \n",
       "2  NaN         NaN        NaN  83.14       0    NaN    NaN        -0.03   \n",
       "3  NaN         NaN        NaN  83.14       0    NaN    NaN        -0.03   \n",
       "4  NaN         NaN        NaN  83.14       0    NaN    NaN        -0.03   \n",
       "\n",
       "   ICULOS  SepsisLabel  \n",
       "0       1            0  \n",
       "1       2            0  \n",
       "2       3            0  \n",
       "3       4            0  \n",
       "4       5            0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data summary:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54 entries, 0 to 53\n",
      "Data columns (total 41 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   HR                49 non-null     float64\n",
      " 1   O2Sat             44 non-null     float64\n",
      " 2   Temp              10 non-null     float64\n",
      " 3   SBP               42 non-null     float64\n",
      " 4   MAP               42 non-null     float64\n",
      " 5   DBP               0 non-null      float64\n",
      " 6   Resp              50 non-null     float64\n",
      " 7   EtCO2             0 non-null      float64\n",
      " 8   BaseExcess        7 non-null      float64\n",
      " 9   HCO3              2 non-null      float64\n",
      " 10  FiO2              4 non-null      float64\n",
      " 11  pH                7 non-null      float64\n",
      " 12  PaCO2             6 non-null      float64\n",
      " 13  SaO2              4 non-null      float64\n",
      " 14  AST               1 non-null      float64\n",
      " 15  BUN               2 non-null      float64\n",
      " 16  Alkalinephos      1 non-null      float64\n",
      " 17  Calcium           2 non-null      float64\n",
      " 18  Chloride          2 non-null      float64\n",
      " 19  Creatinine        2 non-null      float64\n",
      " 20  Bilirubin_direct  0 non-null      float64\n",
      " 21  Glucose           2 non-null      float64\n",
      " 22  Lactate           0 non-null      float64\n",
      " 23  Magnesium         2 non-null      float64\n",
      " 24  Phosphate         2 non-null      float64\n",
      " 25  Potassium         2 non-null      float64\n",
      " 26  Bilirubin_total   1 non-null      float64\n",
      " 27  TroponinI         0 non-null      float64\n",
      " 28  Hct               2 non-null      float64\n",
      " 29  Hgb               2 non-null      float64\n",
      " 30  PTT               0 non-null      float64\n",
      " 31  WBC               2 non-null      float64\n",
      " 32  Fibrinogen        0 non-null      float64\n",
      " 33  Platelets         2 non-null      float64\n",
      " 34  Age               54 non-null     float64\n",
      " 35  Gender            54 non-null     int64  \n",
      " 36  Unit1             0 non-null      float64\n",
      " 37  Unit2             0 non-null      float64\n",
      " 38  HospAdmTime       54 non-null     float64\n",
      " 39  ICULOS            54 non-null     int64  \n",
      " 40  SepsisLabel       54 non-null     int64  \n",
      "dtypes: float64(38), int64(3)\n",
      "memory usage: 17.4 KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the path to the data. \n",
    "# The '..' means go up one directory from 'notebooks' to the main BME folder.\n",
    "# The files are inside the 'physionet.org/files/...' folder created by wget.\n",
    "data_dir = os.path.join('..', 'data', 'raw', 'physionet.org', 'files', 'challenge-2019', '1.0.0', 'training', 'training_setA')\n",
    "\n",
    "# Let's just load the first patient file to start.\n",
    "first_patient_file = 'p000001.psv'\n",
    "file_path = os.path.join(data_dir, first_patient_file)\n",
    "\n",
    "# Load the data. The files are separated by a pipe '|' character.\n",
    "patient_df = pd.read_csv(file_path, sep='|')\n",
    "\n",
    "# Display the first few rows to see what it looks like\n",
    "print(f\"Displaying data for patient: {first_patient_file}\")\n",
    "display(patient_df.head())\n",
    "\n",
    "# Display a summary of the columns, missing values, and data types\n",
    "print(\"\\nData summary:\")\n",
    "patient_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Part 2 (V3 - Corrected and Memory-Efficient) ---\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the data directory\n",
    "data_dir = os.path.join('..', 'data', 'raw', 'physionet.org', 'files', 'challenge-2019', '1.0.0', 'training', 'training_setA')\n",
    "all_patient_files = os.listdir(data_dir)\n",
    "\n",
    "# Initialize variables to store our summary counts\n",
    "list_of_summaries = []\n",
    "total_rows_processed = 0\n",
    "\n",
    "print(f\"Starting memory-efficient analysis of {len(all_patient_files)} files...\")\n",
    "print(\"This will take several minutes, but it will not crash. Please be patient.\")\n",
    "\n",
    "# Loop through every file\n",
    "for i, filename in enumerate(all_patient_files):\n",
    "    full_path = os.path.join(data_dir, filename)\n",
    "    \n",
    "    # Load one file\n",
    "    df = pd.read_csv(full_path, sep='|')\n",
    "    \n",
    "    # Accumulate the counts we need\n",
    "    total_rows_processed += len(df)\n",
    "    list_of_summaries.append(df.notnull().sum()) # Store only the small summary\n",
    "\n",
    "    # After processing, the large 'df' is automatically discarded from memory\n",
    "    # before the next loop starts. This is why it's memory-safe.\n",
    "\n",
    "    # Print progress so you know it's working\n",
    "    if (i + 1) % 2000 == 0:\n",
    "        print(f\"  ... processed {i + 1} / {len(all_patient_files)} files\")\n",
    "\n",
    "print(\"...analysis complete. Combining summaries...\")\n",
    "\n",
    "# Combine the small summaries (this is memory-safe)\n",
    "summary_counts_df = pd.DataFrame(list_of_summaries)\n",
    "\n",
    "# Sum the counts across all files\n",
    "total_non_missing_counts = summary_counts_df.sum()\n",
    "\n",
    "# Calculate the final missing percentage\n",
    "missing_percentage = 100 * (1 - (total_non_missing_counts / total_rows_processed))\n",
    "\n",
    "# Sort and display the results\n",
    "sorted_missing = missing_percentage.sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n--- Analysis of ALL Training Set A Patients ---\")\n",
    "print(\"\\nPercentage of missing data per column (Top 20):\")\n",
    "display(sorted_missing.head(20))\n",
    "\n",
    "print(\"\\nPercentage of missing data per column (Bottom 10 - most complete):\")\n",
    "display(sorted_missing.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e24c9c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing missing values...\n",
      "\n",
      "Data summary after imputation:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 59114 entries, 0 to 59113\n",
      "Data columns (total 11 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   PatientID  59114 non-null  object \n",
      " 1   HR         38773 non-null  float64\n",
      " 2   O2Sat      38698 non-null  float64\n",
      " 3   Temp       38594 non-null  float64\n",
      " 4   SBP        38672 non-null  float64\n",
      " 5   MAP        38758 non-null  float64\n",
      " 6   DBP        26440 non-null  float64\n",
      " 7   Resp       38626 non-null  float64\n",
      " 8   Age        38773 non-null  float64\n",
      " 9   Gender     38773 non-null  float64\n",
      " 10  ICULOS     38773 non-null  float64\n",
      "dtypes: float64(10), object(1)\n",
      "memory usage: 5.4+ MB\n",
      "\n",
      "Remaining missing values after imputation:\n",
      "PatientID        0\n",
      "HR           20341\n",
      "O2Sat        20416\n",
      "Temp         20520\n",
      "SBP          20442\n",
      "MAP          20356\n",
      "DBP          32674\n",
      "Resp         20488\n",
      "Age          20341\n",
      "Gender       20341\n",
      "ICULOS       20341\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legra\\AppData\\Local\\Temp\\ipykernel_22156\\2862577763.py:15: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  preprocessed_df = preprocessed_df.groupby('PatientID').apply(lambda g: g.ffill().bfill())\n"
     ]
    }
   ],
   "source": [
    "# --- Part 3: Preprocessing and Feature Selection (Final Corrected Code) ---\n",
    "\n",
    "# 1. Define the columns we want to keep\n",
    "core_features = [\n",
    "    'PatientID', 'HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', \n",
    "    'Age', 'Gender', 'ICULOS'\n",
    "]\n",
    "\n",
    "# 2. Create a new dataframe with only these columns\n",
    "preprocessed_df = full_df[core_features].copy()\n",
    "\n",
    "# 3. Impute missing values using forward-fill then backward-fill for each patient.\n",
    "# This single line is the most robust way to do this.\n",
    "print(\"Imputing missing values...\")\n",
    "preprocessed_df = preprocessed_df.groupby('PatientID').apply(lambda g: g.ffill().bfill())\n",
    "\n",
    "# The operation above might create a multi-level index. Let's clean it up.\n",
    "preprocessed_df = preprocessed_df.reset_index(level=0, drop=True)\n",
    "\n",
    "\n",
    "# 4. Verify the result\n",
    "print(\"\\nData summary after imputation:\")\n",
    "preprocessed_df.info()\n",
    "\n",
    "print(\"\\nRemaining missing values after imputation:\")\n",
    "print(preprocessed_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6490241a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique patients before final cleaning: 1000\n",
      "Number of unique patients after final cleaning: 637\n",
      "Number of patients removed: 363\n",
      "\n",
      "Data summary of the final, clean dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 26099 entries, 20395 to 59113\n",
      "Data columns (total 11 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   PatientID  26099 non-null  object \n",
      " 1   HR         26099 non-null  float64\n",
      " 2   O2Sat      26099 non-null  float64\n",
      " 3   Temp       26099 non-null  float64\n",
      " 4   SBP        26099 non-null  float64\n",
      " 5   MAP        26099 non-null  float64\n",
      " 6   DBP        26099 non-null  float64\n",
      " 7   Resp       26099 non-null  float64\n",
      " 8   Age        26099 non-null  float64\n",
      " 9   Gender     26099 non-null  float64\n",
      " 10  ICULOS     26099 non-null  float64\n",
      "dtypes: float64(10), object(1)\n",
      "memory usage: 2.4+ MB\n",
      "\n",
      "Saving cleaned data to the 'processed' directory...\n",
      "Data saved to: ..\\data\\processed\\cleaned_sepsis_data.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Part 4: Final Cleaning ---\n",
    "\n",
    "# Let's see how many patients we have before the final drop\n",
    "num_patients_before = preprocessed_df['PatientID'].nunique()\n",
    "print(f\"Number of unique patients before final cleaning: {num_patients_before}\")\n",
    "\n",
    "# Drop any rows that STILL have missing values in any of our core features\n",
    "# This effectively removes patients who had no measurements for one or more vitals.\n",
    "final_df = preprocessed_df.dropna()\n",
    "\n",
    "# Let's see how many patients remain\n",
    "num_patients_after = final_df['PatientID'].nunique()\n",
    "print(f\"Number of unique patients after final cleaning: {num_patients_after}\")\n",
    "print(f\"Number of patients removed: {num_patients_before - num_patients_after}\")\n",
    "\n",
    "\n",
    "# Verify that there are no more missing values\n",
    "print(\"\\nData summary of the final, clean dataset:\")\n",
    "final_df.info()\n",
    "\n",
    "# Let's save this clean dataframe to the 'processed' data folder.\n",
    "# This is Task 2.4 from your README.\n",
    "print(\"\\nSaving cleaned data to the 'processed' directory...\")\n",
    "processed_data_path = os.path.join('..', 'data', 'processed', 'cleaned_sepsis_data.csv')\n",
    "final_df.to_csv(processed_data_path, index=False)\n",
    "print(f\"Data saved to: {processed_data_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
